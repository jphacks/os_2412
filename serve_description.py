# -*- coding: utf-8 -*-
"""serve_description.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cCx0-Um3GBkL5a0LBNQkl1ISJhQBrtg9
"""

!pip install openai pillow gtts pygame

from google.colab import auth
import gspread
from google.auth import default
import pandas as pd
import os

def setup_google_auth():
    """Google認証のセットアップを行う"""
    auth.authenticate_user()
    creds, _ = default()
    gc = gspread.authorize(creds)
    return gc

def update_sheet(spreadsheet_url, data_df):
    """
    Google Sheetsを更新する

    Parameters:
    spreadsheet_url (str): スプレッドシートのURL
    data_df (pandas.DataFrame): 更新するデータ
    """
    gc = setup_google_auth()

    # スプレッドシートを開く
    sh = gc.open_by_url(spreadsheet_url)
    worksheet = sh.get_worksheet(0)  # 最初のワークシート

    # DataFrameをリストに変換
    values = [data_df.columns.values.tolist()] + data_df.values.tolist()

    # ワークシートをクリアして新しいデータを書き込む
    worksheet.clear()
    worksheet.update('A1', values)

def read_sheet(spreadsheet_url):
    """
    Google Sheetsからデータを読み込む

    Parameters:
    spreadsheet_url (str): スプレッドシートのURL

    Returns:
    pandas.DataFrame: 読み込んだデータ
    """
    gc = setup_google_auth()

    # スプレッドシートを開く
    sh = gc.open_by_url(spreadsheet_url)
    worksheet = sh.get_worksheet(0)

    # データを取得してDataFrameに変換
    data = worksheet.get_all_records()
    return pd.DataFrame(data)

# 使用例
"""
# データを更新する場合
spreadsheet_url = "あなたのスプレッドシートのURL"
data = pd.DataFrame({
    'Name': ['John', 'Jane', 'Bob'],
    'Age': [25, 30, 35],
    'City': ['Tokyo', 'Osaka', 'Nagoya']
})
update_sheet(spreadsheet_url, data)

# データを読み込む場合
df = read_sheet(spreadsheet_url)
print(df)
"""

import os
from openai import OpenAI
import requests
from PIL import Image
import io
from gtts import gTTS
from datetime import datetime
import base64

class LocationImageAnalyzer:
    def __init__(self, openai_api_key):
        self.client = OpenAI(api_key=openai_api_key)

    def encode_image_to_base64(self, image_path):
        """画像をbase64エンコードする"""
        with Image.open(image_path) as img:
            # 画像サイズが大きい場合はリサイズ
            max_size = 2048
            if max(img.size) > max_size:
                ratio = max_size / max(img.size)
                new_size = tuple(int(dim * ratio) for dim in img.size)
                img = img.resize(new_size, Image.Resampling.LANCZOS)

            # 画像をJPEGフォーマットでバイト列に変換
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='JPEG')
            img_byte_arr = img_byte_arr.getvalue()

            # base64エンコード
            base64_encoded = base64.b64encode(img_byte_arr).decode('utf-8')
            return base64_encoded

    def analyze_location_and_image(self, image_path, latitude, longitude, model, voice):
        """画像と位置情報を分析する"""
        try:
            # 画像をエンコード
            image_data = self.encode_image_to_base64(image_path)
            messages = [
                  {
                      "role": "user",
                      "content": [
                          {
                              "type": "text",
                              "text": f"この画像は緯度{latitude}、経度{longitude}で撮影されました。"
                                      f"画像の内容と撮影された場所について、名称を交えて詳しく説明してください。緯度と経度は説明に含めないでください。"
                                      f"歴史的背景や周辺の観光スポット、危険な場所、治安についても具体的に触れてください。"
                                      f"説明は日本語で、ガイドが観光客に説明するような親しみやすい口調でお願いします。"
                          },
                          {
                              "type": "image_url",
                              "image_url": {
                                  "url": f"data:image/jpeg;base64,{image_data}"
                              }
                          }
                      ]
                  }
              ]

            if model == "gpt-4o-mini":
                # GPT-4Vによる分析
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    max_tokens=500
                )

                description = response.choices[0].message.content
                return description

            else:
                try:
                    # 画像分析の実行
                    analysis_response = self.client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=messages,
                        max_tokens=500
                    )

                    description = analysis_response.choices[0].message.content

                    # GPT-4V-Audio-Previewによる音声生成
                    audio_response = self.client.audio.speech.create(
                        model="tts-1",  # TTSモデルを使用
                        voice=voice,   # 音声の種類
                        input=description  # 生成したテキスト
                    )

                    # 出力ディレクトリが存在しない場合は作成
                    output_dir = "audio_output"
                    if not os.path.exists(output_dir):
                        os.makedirs(output_dir)
                    # ファイル名に現在時刻を含める
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    audio_file = os.path.join(output_dir, f"description_{timestamp}.wav")

                    # 音声を保存
                    audio_response.stream_to_file(audio_file)

                    print(f"音声ファイルを生成しました: {audio_file}")
                    return {"description": description, "audio_file": audio_file}

                except Exception as e:
                    return f"音声生成でエラーが発生しました: {str(e)}"

        except Exception as e:
            return f"エラーが発生しました: {str(e)}"

    def generate_audio(self, text, model, output_dir="audio_output"):
        """テキストを音声に変換する"""
        try:
            # 出力ディレクトリが存在しない場合は作成
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ファイル名に現在時刻を含める
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            audio_file = os.path.join(output_dir, f"description_{timestamp}.wav")

            # テキストを音声に変換
            tts = gTTS(text=text, lang='ja', slow=False)
            tts.save(audio_file)

            print(f"音声ファイルを生成しました: {audio_file}")
            return audio_file

        except Exception as e:
            return f"音声生成でエラーが発生しました: {str(e)}"

def main():
    # OpenAI APIキーを設定
    openai_api_key = os.getenv("OPENAI_API_KEY")
    model = "gpt-4o-mini"
    # model = "gpt-4o-audio-preview"
    # voice = "alloy"
    voice = "nove"

    # 画像パスと位置情報を設定
    image_path = "/content/mohumohu.jpeg"
    latitude = 27.329167
    longitude = 68.138889

    # アナライザーのインスタンスを作成
    analyzer = LocationImageAnalyzer(openai_api_key)

    if model == "gpt-4o-mini":
        # 画像と位置情報を分析
        description = analyzer.analyze_location_and_image(image_path, latitude, longitude, model, voice)
        print("説明:", description)

        # 音声を生成
        audio_file = analyzer.generate_audio(description, model)
        print(f"音声ファイルが {audio_file} に保存されました")

    else:
        # 画像と位置情報を分析して音声生成
        result = analyzer.analyze_location_and_image(image_path, latitude, longitude, model, voice)
        if isinstance(result, dict):
            print("説明:", result["description"])
            print(f"音声ファイルが {result['audio_file']} に保存されました")
        else:
            print(result)  # エラーメッセージ

if __name__ == "__main__":
    main()

